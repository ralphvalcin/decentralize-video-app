# AI Features - Task-Based Usability Test Scripts

## Overview

This document provides detailed test scripts for conducting moderated usability testing of AI features. Each script includes pre-test setup, specific tasks, success criteria, and data collection methods.

## Test Script Template Structure

Each test script follows this structure:
- **Participant Profile**: Target user type and experience level
- **Pre-Test Setup**: Environment configuration and briefing
- **Task Scenarios**: Detailed task descriptions with context
- **Success Criteria**: Specific measurable outcomes
- **Data Collection**: Metrics and observations to capture
- **Post-Task Questions**: Follow-up questions for insights

## Test Script 1: AI Feature Discovery & First Use

### Participant Profile
- **Target User**: New to platform AI features, basic video conferencing experience
- **Technical Level**: Beginner to Intermediate
- **Duration**: 45 minutes
- **Setting**: Moderated remote session via screen sharing

### Pre-Test Setup

#### Environment Configuration
- Clean browser instance (no previous AI feature exposure)
- Test meeting room with 2-3 simulated participants
- AI features enabled with realistic recommendation scenarios
- Connection quality simulator ready for testing

#### Facilitator Brief
- Don't mention AI features before user discovers them naturally
- Prepare prompting questions for think-aloud protocol
- Have backup scenarios ready if primary ones don't trigger AI
- Document first reactions and discovery moments

#### Participant Introduction
"Today we're testing some new features in our video conferencing platform. I'll ask you to complete some typical meeting tasks. Please think out loud as you work, sharing what you're noticing, thinking, and feeling. There are no right or wrong answers - we're learning how to improve the platform."

### Task Scenarios

#### Task 1: Join Meeting and Discover AI Features
**Scenario Context**: "You're joining a team meeting to discuss quarterly results. Other participants are already in the call."

**Task Instructions**:
1. Join the meeting room (URL provided)
2. Set up your camera and microphone as you normally would
3. Take a moment to familiarize yourself with the interface
4. Notice what's different or new compared to basic video calling

**Facilitator Observations**:
- [ ] Time to notice AI badge (target: <3 minutes)
- [ ] User's first reaction to AI badge
- [ ] Whether user investigates badge without prompting
- [ ] User's interpretation of badge purpose
- [ ] Any confusion or uncertainty expressed

**Success Criteria**:
- User notices AI badge within 3 minutes
- User correctly identifies badge as AI-related feature
- User shows curiosity about badge functionality
- User attempts to interact with badge

**Think-Aloud Prompts**:
- "What are you noticing about the interface?"
- "Tell me about any elements that catch your attention"
- "What do you think that [badge] might do?"

#### Task 2: First AI Dashboard Exploration
**Scenario Context**: "You notice there's some kind of AI feature available. You're curious about what it might offer."

**Task Instructions**:
1. Explore the AI feature you discovered
2. Try to understand what information it provides
3. Look for anything that might help improve your meeting experience

**Facilitator Observations**:
- [ ] User successfully opens AI dashboard
- [ ] Which tab user explores first
- [ ] User's understanding of information presented
- [ ] Level of information overwhelm or comfort
- [ ] User's strategy for navigating dashboard

**Success Criteria**:
- User successfully opens AI dashboard
- User explores at least 2 dashboard tabs
- User demonstrates understanding of at least one AI feature
- User doesn't express frustration with complexity

**Think-Aloud Prompts**:
- "What information are you seeing here?"
- "How would you describe what this AI system does?"
- "What seems most useful or interesting to you?"

#### Task 3: Act on First AI Recommendation
**Scenario Context**: "The AI system is making a recommendation about your meeting. You need to decide whether to follow its advice."

**Task Instructions**:
1. Find any recommendations the AI system is making
2. Understand what action it's suggesting
3. Decide whether to follow the recommendation and explain why
4. Take the recommended action if you choose to

**Facilitator Observations**:
- [ ] User locates AI recommendations
- [ ] User understands recommendation clearly
- [ ] User's decision-making process
- [ ] Confidence level in following AI advice
- [ ] Outcome satisfaction after taking action

**Success Criteria**:
- User finds AI recommendations without assistance
- User understands what action is being recommended
- User makes informed decision about following advice
- User successfully executes chosen action

**Think-Aloud Prompts**:
- "What is the AI suggesting you do?"
- "How confident do you feel about this recommendation?"
- "What would help you decide whether to follow this advice?"

### Post-Test Interview Questions

#### Discovery Experience
1. "How did you first notice the AI features? Was it clear what they were?"
2. "What was your initial impression when you saw the AI badge?"
3. "Did you feel the AI features were introduced at the right time?"

#### Understanding & Mental Model
4. "In your own words, what does this AI system do?"
5. "What are the main benefits you see from these AI features?"
6. "Are there any aspects that seem unclear or confusing?"

#### Trust & Confidence
7. "How comfortable do you feel relying on AI recommendations?"
8. "What information helps you decide whether to trust an AI suggestion?"
9. "What concerns, if any, do you have about AI making recommendations?"

#### Value Perception
10. "Which AI feature seems most valuable to you? Why?"
11. "Are there any AI features that don't seem useful for your needs?"
12. "How likely would you be to use these AI features in real meetings?"

### Data Collection Methods

#### Quantitative Metrics
- Time to discover AI badge (seconds)
- Number of dashboard tabs explored
- Percentage of AI recommendations followed
- Task completion rate (%)
- Time to complete each task (minutes)

#### Qualitative Observations
- First reaction to AI badge (positive/neutral/negative)
- Level of confusion or uncertainty expressed
- Questions asked about AI functionality
- Evidence of understanding AI capabilities
- Emotional responses during AI interactions

## Test Script 2: AI Feature Integration & Workflow

### Participant Profile
- **Target User**: Familiar with AI features, regular meeting attendee
- **Technical Level**: Intermediate
- **Duration**: 60 minutes
- **Setting**: Realistic meeting simulation with connection issues

### Pre-Test Setup

#### Environment Configuration
- AI features enabled with participant's previous settings
- Simulated connection quality degradation during test
- Meeting scenario with presentation and discussion phases
- Multiple AI recommendation scenarios prepared

### Task Scenarios

#### Task 4: Proactive AI Monitoring
**Scenario Context**: "You're hosting an important client presentation. You want to ensure the best possible meeting experience."

**Task Instructions**:
1. Before starting your presentation, check what AI insights are available
2. Use AI information to optimize your setup
3. Monitor AI feedback during the presentation

**Success Criteria**:
- User proactively checks AI dashboard before presenting
- User takes preventive actions based on AI insights
- User monitors AI feedback during presentation
- User maintains awareness without disrupting presentation flow

#### Task 5: AI-Assisted Problem Resolution
**Scenario Context**: "During your meeting, you notice connection quality starting to degrade. The AI system is detecting issues."

**Task Instructions**:
1. Notice when connection quality issues arise
2. Use AI diagnostics to understand the problem
3. Follow AI recommendations to resolve issues
4. Assess whether the resolution was effective

**Success Criteria**:
- User recognizes connection quality problems early
- User successfully accesses AI diagnostic information
- User follows AI troubleshooting recommendations
- User evaluates effectiveness of AI solutions

#### Task 6: AI-Enhanced Meeting Management
**Scenario Context**: "You're managing a team discussion and want to ensure good participation from all attendees."

**Task Instructions**:
1. Use AI insights to monitor meeting engagement
2. Identify any participation imbalances
3. Take actions to improve overall meeting dynamics
4. Review AI feedback on your interventions

**Success Criteria**:
- User utilizes engagement insights effectively
- User identifies participation patterns from AI data
- User takes appropriate actions to improve engagement
- User understands impact of interventions through AI feedback

### Data Collection Methods

#### Behavioral Metrics
- Frequency of AI dashboard checks
- Response time to AI alerts (seconds)
- Success rate of AI-recommended actions (%)
- User-initiated vs AI-prompted interactions

#### Performance Outcomes
- Meeting quality improvements with AI assistance
- Problem resolution time with AI vs without AI
- Participant engagement scores before/after AI interventions

## Test Script 3: Accessibility-Focused AI Testing

### Participant Profile
- **Target User**: Uses assistive technology (screen reader, keyboard navigation, voice control)
- **Technical Level**: Varies
- **Duration**: 90 minutes
- **Setting**: User's preferred assistive technology setup

### Pre-Test Setup

#### Accessibility Environment
- User's preferred screen reader enabled (NVDA, JAWS, VoiceOver)
- Keyboard-only navigation required
- High contrast or custom display settings respected
- Any user-specific accessibility preferences configured

### Task Scenarios

#### Task 7: Accessible AI Discovery
**Scenario Context**: "Discover and explore AI features using only your preferred assistive technology."

**Task Instructions**:
1. Join meeting and discover AI features using screen reader
2. Navigate AI dashboard using keyboard only
3. Access AI recommendations through assistive technology
4. Configure AI settings accessibly

**Success Criteria**:
- User discovers AI features through assistive technology
- User navigates AI interface completely via keyboard
- All AI content accessible via screen reader
- User can configure AI settings independently

#### Task 8: Accessible AI Interaction
**Scenario Context**: "Interact with AI recommendations and insights using assistive technology."

**Task Instructions**:
1. Receive and understand AI notifications through screen reader
2. Access detailed AI insights via keyboard navigation
3. Execute AI-recommended actions accessibly
4. Provide feedback on AI recommendations

**Success Criteria**:
- AI notifications properly announced by screen reader
- User accesses all AI content via assistive technology
- User successfully executes AI recommendations
- User can provide input back to AI system

### Accessibility-Specific Data Collection

#### Technical Accessibility
- WCAG 2.1 AA compliance verification
- Screen reader compatibility across features
- Keyboard navigation completeness
- Focus management effectiveness

#### User Experience Accessibility
- Cognitive load with assistive technology
- Information processing efficiency
- Task completion confidence
- Overall accessibility satisfaction

## Test Script 4: Long-Term Adoption & Mastery

### Participant Profile
- **Target User**: Experienced with AI features, power user potential
- **Technical Level**: Advanced
- **Duration**: 75 minutes
- **Setting**: Complex meeting scenarios with multiple AI decision points

### Task Scenarios

#### Task 9: Advanced AI Customization
**Task Instructions**:
1. Customize AI recommendation thresholds to match preferences
2. Configure AI notification settings for different meeting types
3. Set up AI data export and reporting preferences
4. Create personal AI usage patterns

#### Task 10: AI Feature Evangelism
**Task Instructions**:
1. Demonstrate AI features to a colleague (role-play)
2. Explain specific benefits and use cases
3. Help colleague configure AI settings
4. Share AI insights and recommendations

### Advanced User Data Collection
- Feature adoption depth and breadth
- Customization usage patterns
- Advocacy and sharing behaviors
- Advanced feature requests and feedback

## Cross-Script Success Metrics

### Universal Success Criteria
- **Task Completion Rate**: >90% across all user types
- **User Satisfaction**: >4.0/5.0 average rating
- **Feature Adoption**: >60% continued usage after testing
- **Recommendation Trust**: >70% willingness to follow AI advice

### Accessibility Success Criteria
- **Full Keyboard Navigation**: 100% feature accessibility
- **Screen Reader Compatibility**: 100% content accessibility
- **Task Completion Parity**: Equal success rates for assistive technology users
- **Satisfaction Parity**: Equal satisfaction scores across access methods

## Post-Testing Analysis Framework

### Quantitative Analysis
- Statistical significance testing of completion rates
- Time-to-completion comparisons across user types
- Error rate analysis by task and user type
- Feature adoption correlation analysis

### Qualitative Analysis
- Thematic analysis of user feedback
- Mental model identification and comparison
- Trust factor analysis
- Barrier and friction point identification

This comprehensive test script collection provides systematic evaluation of AI features across user types, accessibility needs, and usage contexts, ensuring thorough UX validation before deployment.